{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Starter code. Finished implementing the methods in this code\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import glob\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy.sql import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Fill in the __init__() method so it takes a filepath to a CSV file and loads that CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    \"\"\"\n",
    "    Loads a CSV file path into a Dataframe\n",
    "\n",
    "    Args:\n",
    "        filepath (str): file path to the CSV file\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath:str, index=None, multi_file_load=False) -> None:\n",
    "        # if statement to load files and set index\n",
    "        \n",
    "        if multi_file_load:\n",
    "            # load multiple files\n",
    "            store = []\n",
    "            for filenum, filename in enumerate(glob(filepath)):\n",
    "                # logger.info(f\"\\tLoading file number {filenum}\")\n",
    "                tmp = pd.read_csv(filename, header=0)\n",
    "                store.append(tmp)\n",
    "            keep_index = index is None\n",
    "            df = pd.concat(store, axis=0, ignore_index=keep_index)\n",
    "        # Load a single file\n",
    "        else:\n",
    "            df = pd.read_csv(filepath, header=0)\n",
    "        # Set index of our data\n",
    "        if index is not None:\n",
    "            df = df.set_index(index)\n",
    "        self.df = df\n",
    "        # pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "artists_file = data_dir + 'spotify_artists.csv'\n",
    "albums_file = data_dir + 'spotify_albums.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Fill in the head() method so it prints the head of the DataFrame.\n",
    "def head(self) -> None:\n",
    "    \"\"\"\n",
    "    prints the head of the dataframe to console\n",
    "    \"\"\"\n",
    "    print(self.df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artists = pd.read_csv(artists_file, header=0)\n",
    "# albums = pd.read_csv(albums_file, header=0)\n",
    "# print(artists.head())\n",
    "\n",
    "# If you want to see more rows, you can specify that when calling head():\n",
    "# print(albums.head(12))\n",
    "\n",
    "def head(self) -> None:\n",
    "    \"\"\"\n",
    "    prints the head of the dataframe to console\n",
    "    \"\"\"\n",
    "    print(self.df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index(self, col_list, index_name=\"index\") -> None:\n",
    "        \"\"\"\n",
    "        Creates an index by concatenating columns values\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        # Concatenates columns, calls it col_list and turns it into the primary key aka index\n",
    "        df[index_name] = df[col_list].apply(lambda row: \"-\".join(row.values.astype(str)), axis = 1)\n",
    "        df.set_index(index_name, inplace = True)\n",
    "        # replaces whatever the index used to be with our shiny, new, smushed up index\n",
    "        self.df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_index(self, index_name:str, colum_names:list) -> None:\n",
    "#         \"\"\"\n",
    "#         Create a dataframe index column from concatenating a series of column values. Column values are concatenated by a dash \"-\".\n",
    "\n",
    "#         For example if you have three columns such as: artist=\"Metallica\", song=\"Ride the Lighting\"\n",
    "#         the index would be \"\"Metallica-Ride the Lighting\"\n",
    "\n",
    "#         Args:\n",
    "#             index_name (str): the index column name\n",
    "#             colum_names (list): list of columns to concatenate into an index column\n",
    "#         \"\"\"\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     # - Fill in the sort() method so it sorts the DataFrame by a specified column.\n",
    "#     def sort(self, column_name:str) -> None:\n",
    "#         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#         Sorts the dataframe by a particular column\n",
    "\n",
    "#         Args:\n",
    "#             column_name (str): column name to sort by\"\"\"\n",
    "\n",
    "def sort(self, column_name:str) -> None:\n",
    "    df = self.df\n",
    "    # sorts the dataframe by a later specified column\n",
    "    df.sort_values(column_name)\n",
    "    self.df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Outside the DataLoader class, fill in the db_engine() function to create a SQLAlchemy database engine. For this project, the values needed to configure it can be passed in as arguments, rather than using a config file.\n",
    "\"\"\"\n",
    "def db_engine(db_host:str, db_user:str, db_pass:str, db_name:str=\"spotify\") -> sa.engine.Engine:\n",
    "    #create enginge\n",
    "    engine = create_engine(f'mysql+pymysql://{db_user}:{db_pass}@{db_host}/{db_name}', future = True)\n",
    "    metadata = MetaData(bind=engine)\n",
    "    conn = engine.connect()\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Using SqlAlchemy, create a database engine and return it\n",
    "\n",
    "    Args:\n",
    "        db_host (str): datbase host and port settings\n",
    "        db_user (str): database user\n",
    "        db_pass (str): database password\n",
    "        db_name (str): database name, defaults to \"spotify\"\n",
    "\n",
    "    Returns:\n",
    "        sa.engine.Engine: sqlalchemy engine\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(self, db_engine, db_table_name:str) -> None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Loads the dataframe into a database table.\n",
    "\n",
    "    Args:\n",
    "        db_engine (SqlAlchemy Engine): SqlAlchemy engine (or connection) to use to insert into database\n",
    "        db_table_name (str): name of database table to insert to\n",
    "    \"\"\"\n",
    "class DataTable():\n",
    "    \"\"\"Create an object that can update the data in our mariaDB tables\"\"\"\n",
    "\n",
    "    def db_engine(db_host:str, db_user:str, db_pass:str, db_name:str=\"spotify\") -> sa.engine.Engine:\n",
    "        super().__init__()\n",
    "        \"\"\"Loads the dataframe into a database table.\"\"\"\n",
    "            # create an engine and connection to our docker mariadb\n",
    "        db_host = config['db_host'] if db_host is None else db_host\n",
    "        db_user = config['db_user'] if db_user is None else db_user\n",
    "        db_pass = config['db_pass'] if db_pass is None else db_pass\n",
    "        db_name = config['db_name'] if db_name is None else db_name\n",
    "\n",
    "        engine = create_engine(f\"mysql+pymysql://{db_user}:{db_pass}@{db_host}/{db_name}\", future=True)\n",
    "        metadata = MetaData(bind=engine)\n",
    "        conn = engine.connect()\n",
    "        self.engine = engine\n",
    "        self.metadata = metadata\n",
    "        self.conn = conn\n",
    "\n",
    "    def open(self):\n",
    "        conn = self.engine.connect()\n",
    "        self.conn = conn\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        conn = self.conn\n",
    "        conn.close()\n",
    "\n",
    "        self.df.to_sql(name=db_table_name, con=self.engine, if_exists='append', chunksize=2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def db_engine(db_host:str, db_user:str, db_pass:str, db_name:str=\"spotify\") -> sa.engine.Engine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the db_create_tables() function to create tables for the Spotify data. The schemas for the tables should reflect the column names and datatypes of the CSV files. You can inspect the column names and datatypes either by opening the CSV file, or by using the following code snippet: ```python import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46321/4109537245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdb_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#define columns from the artists table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m artists_table = Table(\"artists\", metadata,\n\u001b[1;32m      5\u001b[0m     \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'artist_poularity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db_engine' is not defined"
     ]
    }
   ],
   "source": [
    "meta = sa.MetaData(bind=db_engine)\n",
    "\n",
    "#define columns from the artists table\n",
    "artists_table = Table(\"artists\", metadata,\n",
    "    Column('artist_poularity', Numeric),\n",
    "    Column('followers', Numeric),\n",
    "    Column('genres', String(10240)),\n",
    "    Column('id', Numeric, primary_key=True),\n",
    "    Column('name', String(256)),\n",
    "    Column('track_id', String(256)),\n",
    "    Column('track_name_prev', String(256)),\n",
    "    Column('type', String(256)),\n",
    "    extend_existing=True\n",
    ")\n",
    "# ,artist_popularit~y,followers,genres,id,name,track_id,track_name_prev,type\n",
    "#define columns from the albums table\n",
    "albums_table = Table(\"albums\", metadata,\n",
    "    Column('album_type', String(256)),\n",
    "    Column('artist_id', String(256)),\n",
    "    Column('available_markets', String(10240)),\n",
    "    Column('external_urls', String(256)),\n",
    "    Column('href', String(256)),\n",
    "    Column('id', String(256), primary_key=True),\n",
    "    Column('images', String(10340)),\n",
    "    Column('name', String(10240)),\n",
    "    Column('release_date', DateTime, nullable=True),\n",
    "    Column('release_date_precision', String(256)),\n",
    "    Column('total_tracks', Numeric),\n",
    "    Column('track_id', String(256)),\n",
    "    Column('track_name_prev', String(256)),\n",
    "    Column('uri', String(256)),\n",
    "    Column('type', String(256)),\n",
    "    extend_existing=True\n",
    ")\n",
    "# album_type,artist_id,available_markets,external_urls,href,id,images,name,release_date,release_date_precision,total_tracks,track_id,track_name_prev,uri,type\n",
    "\n",
    "#drop tables is drop_first = True\n",
    "if drop_first:\n",
    "    metadata.drop_all()\n",
    "\n",
    "#create tables\n",
    "metadata.create_all(checkfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def db_engine(db_host:str, db_user:str, db_pass:str, db_name:str=\"spotify\") -> sa.engine.Engine:\n",
    "#     \"\"\"Using SqlAlchemy, create a database engine and return it\n",
    "\n",
    "#     Args:\n",
    "#         db_host (str): datbase host and port settings\n",
    "#         db_user (str): database user\n",
    "#         db_pass (str): database password\n",
    "#         db_name (str): database name, defaults to \"spotify\"\n",
    "\n",
    "#     Returns:\n",
    "#         sa.engine.Engine: sqlalchemy engine\n",
    "#     \"\"\"\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def db_create_tables(db_engine, drop_first:bool = False) -> None:\n",
    "#     \"\"\"\n",
    "#     Using SqlAlchemy Metadata class create two spotify tables (including their schema columns and types)\n",
    "#     for **artists** and **albums**.\n",
    "\n",
    "\n",
    "#     Args:\n",
    "#         db_engine (SqlAlchemy Engine): SqlAlchemy engine to bind the metadata to.\n",
    "#         drop_first (bool): Drop the tables before creating them again first. Default to False\n",
    "#     \"\"\"\n",
    "#     meta = sa.MetaData(bind=db_engine)\n",
    "\n",
    "#     # your code to define tables go in here\n",
    "#     #   - Be careful, some of the columns like album.available_markets are very long. Make sure you give enough DB length for these. ie: 10240 (10kb)\n",
    "\n",
    "#     # your code to drop and create tables go here\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Pipeline Orchestratation method.\n",
    "\n",
    "#     Performs the following:\n",
    "#     - Creates a DataLoader instance for artists and albums\n",
    "#     - prints the head for both instances\n",
    "#     - Sets artists index to id column\n",
    "#     - Sets albums index to artist_id, name, and release_date\n",
    "#     - Sorts artists by name\n",
    "#     - creates database engine\n",
    "#     - creates database metadata tables/columns\n",
    "#     - loads both artists and albums into database\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "200472f4080f6edd95fb2a2d21e5691bf6f38c6fea4fdcb118da3eb4bf8b747d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
